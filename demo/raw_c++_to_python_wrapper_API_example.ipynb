{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw example of API usage in Python of the C++ wrapper classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not rely on any python overlay for now, as we want to expose how C++ pybind11 classes look like from a python point of view.\n",
    "\n",
    "The `import pyclesperanto as pycle` will import the python package directly linked to the `_pyclesperanto.so` library file.\n",
    "\n",
    "This notebook is mainly here to highlyt what is currently visible from the C++ and provide discussion material for the design and implementation of a pure python layer API over it, similar to pyclesperanto-prototype for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyclesperanto as pycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After imports, we need to allocated a device. This requires to instanciate a gpu object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NVIDIA CUDA - NVIDIA GeForce GTX 1050 Ti]\n",
      "\tDevicedeviceType: 4\n",
      "\tMaxComputeUnits: 6\n",
      "\tMaxClockFrequency: 1455\n",
      "\tVersion: OpenCL 3.0 CUDA\n",
      "\tExtensions: cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts cl_nv_create_buffer cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_device_uuid cl_khr_pci_bus_info\n",
      "\tGlobalMemorySizeInBytes: 4233035776\n",
      "\tLocalMemorySizeInBytes: 49152\n",
      "\tMaxMemoryAllocationSizeInBytes: 1058258944\n",
      "\tMaxWorkGroupSize: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = pycle.gpu()\n",
    "print(device.info()) # the print is required in order to keep the formating from c++\n",
    "                     # the () are required as info() it is a c++ class method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to select a specific device using a string key word contained in its name, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NVIDIA CUDA - NVIDIA GeForce GTX 1050 Ti]\n",
      "\tDevicedeviceType: 4\n",
      "\tMaxComputeUnits: 6\n",
      "\tMaxClockFrequency: 1455\n",
      "\tVersion: OpenCL 3.0 CUDA\n",
      "\tExtensions: cl_khr_global_int32_base_atomics cl_khr_global_int32_extended_atomics cl_khr_local_int32_base_atomics cl_khr_local_int32_extended_atomics cl_khr_fp64 cl_khr_3d_image_writes cl_khr_byte_addressable_store cl_khr_icd cl_khr_gl_sharing cl_nv_compiler_options cl_nv_device_attribute_query cl_nv_pragma_unroll cl_nv_copy_opts cl_nv_create_buffer cl_khr_int64_base_atomics cl_khr_int64_extended_atomics cl_khr_device_uuid cl_khr_pci_bus_info\n",
      "\tGlobalMemorySizeInBytes: 4233035776\n",
      "\tLocalMemorySizeInBytes: 49152\n",
      "\tMaxMemoryAllocationSizeInBytes: 1058258944\n",
      "\tMaxWorkGroupSize: 1024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device.select_device(\"GTX\")\n",
    "print(device.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on gpu in module pyclesperanto._pyclesperanto object:\n",
      "\n",
      "class gpu(pybind11_builtins.pybind11_object)\n",
      " |  gpu class wrapper\n",
      " |  -----------------------\n",
      " |  select_device()\n",
      " |  info()\n",
      " |  name()\n",
      " |  score()\n",
      " |  set_wait_for_kernel_to_finish()\n",
      " |  \n",
      " |  create()\n",
      " |  push()\n",
      " |  pull()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      gpu\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      __init__(*args, **kwargs)\n",
      " |      Overloaded function.\n",
      " |      \n",
      " |      1. __init__(self: pyclesperanto._pyclesperanto.gpu) -> None\n",
      " |      \n",
      " |      GPU default constructor\n",
      " |      \n",
      " |      2. __init__(self: pyclesperanto._pyclesperanto.gpu, t_device_name: str, t_device_type: str = 'all') -> None\n",
      " |      \n",
      " |      GPU constructor\n",
      " |  \n",
      " |  create(...)\n",
      " |      create(self: pyclesperanto._pyclesperanto.gpu, dimensions: numpy.ndarray[numpy.float32], t_type: str = 'buffer') -> PyData\n",
      " |      \n",
      " |      create an empty gpu array\n",
      " |  \n",
      " |  info(...)\n",
      " |      info(self: pyclesperanto._pyclesperanto.gpu) -> str\n",
      " |      \n",
      " |      return device informations\n",
      " |  \n",
      " |  name(...)\n",
      " |      name(self: pyclesperanto._pyclesperanto.gpu) -> str\n",
      " |      \n",
      " |      return device name\n",
      " |  \n",
      " |  pull(...)\n",
      " |      pull(self: pyclesperanto._pyclesperanto.gpu, gpu_array: PyData) -> numpy.ndarray[numpy.float32]\n",
      " |      \n",
      " |      read a gpu array into numpy\n",
      " |  \n",
      " |  push(...)\n",
      " |      push(self: pyclesperanto._pyclesperanto.gpu, ndarray: numpy.ndarray[numpy.float32], t_type: str = 'buffer') -> PyData\n",
      " |      \n",
      " |      create a gpu array and write numpy array into it\n",
      " |  \n",
      " |  score(...)\n",
      " |      score(self: pyclesperanto._pyclesperanto.gpu) -> float\n",
      " |      \n",
      " |      return device score\n",
      " |  \n",
      " |  select_device(...)\n",
      " |      select_device(self: pyclesperanto._pyclesperanto.gpu, t_device_name: str, t_device_type: str = 'all') -> None\n",
      " |      \n",
      " |      select device from string, return full device name string\n",
      " |  \n",
      " |  set_wait_for_kernel_to_finish(...)\n",
      " |      set_wait_for_kernel_to_finish(self: pyclesperanto._pyclesperanto.gpu, t_flag: bool = True) -> None\n",
      " |      \n",
      " |      Force device to wait until kernel finished\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycle.gpu()) # help documentation generated from the class, \n",
    "                  # it reveal the associated methods and their signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gpu` class is in charge of managing the device interation, this includes the `create`, `push`, `pull` operations.\n",
    "- create(array, string) allows to allocate memory on the device corresponding to the shape passed in arguments\n",
    "- push(array, string) also create and write the memory on the device from a numpy array shape and data past in argument\n",
    "- pull(gpu_array) will read the memory from the device and return a numpy array\n",
    "\n",
    "With the exception of `pull`, all have a string arguments which allows to decide the type of memory hold is used in the device, a `buffer` or an `image`. The default behaviour is `buffer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## host to device to host behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPU objects defined by the python class `data` can be buffers (default) or images, and will for now only contain float32 data type.\n",
    "Same as the `gpu` class, it comes with several methods similar to the python numpy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on data in module pyclesperanto._pyclesperanto object:\n",
      "\n",
      "class data(pybind11_builtins.pybind11_object)\n",
      " |  data class wrapper\n",
      " |  -----------------------\n",
      " |  ndim()\n",
      " |  size()\n",
      " |  shape()\n",
      " |  shape_xyz()\n",
      " |  shape_zyx()\n",
      " |  dtype()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      data\n",
      " |      pybind11_builtins.pybind11_object\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(...)\n",
      " |      __init__(self: pyclesperanto._pyclesperanto.data) -> None\n",
      " |  \n",
      " |  dtype(...)\n",
      " |      dtype(self: pyclesperanto._pyclesperanto.data) -> str\n",
      " |      \n",
      " |      return object data type (float, double, etc.)\n",
      " |  \n",
      " |  ndim(...)\n",
      " |      ndim(self: pyclesperanto._pyclesperanto.data) -> int\n",
      " |      \n",
      " |      return object dimensionality\n",
      " |  \n",
      " |  shape(...)\n",
      " |      shape(self: pyclesperanto._pyclesperanto.data) -> List[int[3]]\n",
      " |      \n",
      " |      return object shape (x,y,z)\n",
      " |  \n",
      " |  shape_xyz(...)\n",
      " |      shape_xyz(self: pyclesperanto._pyclesperanto.data) -> List[int[3]]\n",
      " |      \n",
      " |      return object shape (x,y,z)\n",
      " |  \n",
      " |  shape_zyx(...)\n",
      " |      shape_zyx(self: pyclesperanto._pyclesperanto.data) -> List[int[3]]\n",
      " |      \n",
      " |      return object shape (z,y,x)\n",
      " |  \n",
      " |  size(...)\n",
      " |      size(self: pyclesperanto._pyclesperanto.data) -> int\n",
      " |      \n",
      " |      return object size (elements wise)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pybind11_builtins.pybind11_object:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from pybind11_builtins.pybind11_type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycle.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gpu device class is the only way to properly create a GPU object throught the commande usage `push` and `create`.\n",
    "And the only way to read its contend is to first `pull` it from the device into the host memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create an array on the host side\n",
    "input_array = np.random.rand(2,5,10)\n",
    "# we push the array from the host to the device as a buffer\n",
    "gpu_input_array = device.push(input_array, \"buffer\")\n",
    "# we create an output memory space (an image, not a buffer this time) on the device of the same size as the input\n",
    "gpu_output_array = device.create(input_array.shape, \"image\")\n",
    "# we can read then from device to host\n",
    "output_array = device.pull(gpu_input_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host input numpy array:\t <class 'numpy.ndarray'> (2, 5, 10) float64\n",
      "device buffer array:\t <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 2] float\n",
      "device image array:\t <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 2] float\n",
      "host output numpy array: <class 'numpy.ndarray'> (2, 5, 10) float32\n"
     ]
    }
   ],
   "source": [
    "print(\"host input numpy array:\\t\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"device buffer array:\\t\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"device image array:\\t\", type(gpu_output_array), gpu_output_array.shape(), gpu_output_array.dtype())\n",
    "print(\"host output numpy array:\", type(output_array), output_array.shape, output_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When push or create on the device, both methods automatically flip the data dimensions from numpy standard (zyx) to C++ (xyz), it is flipped again when reading from device to host.\n",
    "Few details to notice:\n",
    "- C++ class methods requires `()`\n",
    "- C++ `shape()` method return a list, not a tuple like numpy\n",
    "- C++ `dtype()` method display the type according to C++ native types, here `float` corresponding to `float32`\n",
    "- pull return array type is `float32` not `float64` like the input was\n",
    "\n",
    "it is possible to display the shape in the standard we wish, though is is purely visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default display: <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 2] float\n",
      "zyx display: <class 'pyclesperanto._pyclesperanto.data'> [2, 5, 10] float\n",
      "xyz zdisplay: <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 2] float\n"
     ]
    }
   ],
   "source": [
    "print(\"default display:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"zyx display:\", type(gpu_input_array), gpu_input_array.shape_zyx(), gpu_input_array.dtype())\n",
    "print(\"xyz zdisplay:\", type(gpu_input_array), gpu_input_array.shape_xyz(), gpu_input_array.dtype())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More example for various data shape to see code behaviour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with shape (1,5,10)\n",
      "\thost input array: <class 'numpy.ndarray'> (1, 5, 10) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> (5, 10) float32\n",
      "Test with shape (5,10)\n",
      "\thost input array: <class 'numpy.ndarray'> (5, 10) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [10, 5, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> (5, 10) float32\n",
      "Test with shape (1,1,10)\n",
      "\thost input array: <class 'numpy.ndarray'> (1, 1, 10) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [10, 1, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> (10,) float32\n",
      "Test with shape (10)\n",
      "\thost input array: <class 'numpy.ndarray'> (10,) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [10, 1, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> (10,) float32\n",
      "Test with shape (1,1,1)\n",
      "\thost input array: <class 'numpy.ndarray'> (1, 1, 1) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [1, 1, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> () float32\n",
      "Test with shape (1)\n",
      "\thost input array: <class 'numpy.ndarray'> (1,) float64\n",
      "\tdevice array: <class 'pyclesperanto._pyclesperanto.data'> [1, 1, 1] float\n",
      "\thost output array: <class 'numpy.ndarray'> () float32\n"
     ]
    }
   ],
   "source": [
    "print(\"Test with shape (1,5,10)\")\n",
    "input_array = np.random.rand(1,5,10)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)\n",
    "\n",
    "print(\"Test with shape (5,10)\")\n",
    "input_array = np.random.rand(5,10)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)\n",
    "\n",
    "print(\"Test with shape (1,1,10)\")\n",
    "input_array = np.random.rand(1,1,10)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)\n",
    "\n",
    "print(\"Test with shape (10)\")\n",
    "input_array = np.random.rand(10)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)\n",
    "\n",
    "print(\"Test with shape (1,1,1)\")\n",
    "input_array = np.random.rand(1,1,1)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)\n",
    "\n",
    "print(\"Test with shape (1)\")\n",
    "input_array = np.random.rand(1)\n",
    "gpu_input_array = device.push(input_array)\n",
    "output_array = device.pull(gpu_input_array)\n",
    "print(\"\\thost input array:\", type(input_array), input_array.shape, input_array.dtype)\n",
    "print(\"\\tdevice array:\", type(gpu_input_array), gpu_input_array.shape(), gpu_input_array.dtype())\n",
    "print(\"\\thost output array:\", type(output_array), output_array.shape, output_array.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels usage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here kernels would correspond to an image processing operation to be executed on the device. By convention nearly all kernels take as parameters as input and an output, both already defined by the user.\n",
    "\n",
    "Their visibility through the pyclesperanto package is direct, for example `from pyclesperanto import add_image_and_scalar` will make the `add_image_and_scalar` kernel available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# host data\n",
    "input_array = np.random.rand(2,3,4).astype(np.float32)\n",
    "\n",
    "# device input and output\n",
    "gpu_input  = device.push(input_array)\n",
    "gpu_output = device.create(input_array.shape)\n",
    "\n",
    "# execute kernel\n",
    "pycle.add_image_and_scalar(device=device, input=gpu_input, output=gpu_output, scalar=100)\n",
    "\n",
    "# read output from device to host\n",
    "result_array = device.pull(gpu_output)\n",
    "valid_array = input_array + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu output= 2412.063 , vs host output= 2412.063\n"
     ]
    }
   ],
   "source": [
    "print( \"gpu output=\", np.sum(result_array), \", vs host output=\" , np.sum(valid_array) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important point to raise:\n",
    "- All kernel operation first argument is always the device.\n",
    "- C++ side already allows to define arguments tags, those will normally mimic the one used in the CLIc\n",
    "- As arguments tags are available, the arguments order is flexible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu output= 2412.063 , vs host output= 2412.063\n"
     ]
    }
   ],
   "source": [
    "pycle.add_image_and_scalar(output=gpu_output, device=device, scalar=100, input=gpu_input)\n",
    "print( \"gpu output=\", np.sum(result_array), \", vs host output=\" , np.sum(valid_array) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently these kernels are organised per tiers (tier1, tier2, etc.) depending on dependency. Tier2 kernel will requiere one or more kernel from tier1, etc.\n",
    "Their are not linked to any class so far and are directly accessible as function of the package.\n",
    "This is the reason why the device is required as a parameter, but it offers a better flexibility of imports.\n",
    "\n",
    "Documentation and signature is available with the help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function add_image_and_scalar in module pyclesperanto._pyclesperanto:\n",
      "\n",
      "add_image_and_scalar(...) method of builtins.PyCapsule instance\n",
      "    add_image_and_scalar(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data, scalar: float = 0) -> None\n",
      "    \n",
      "    Add buffer and scalar\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycle.add_image_and_scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a more global view of the package is also available with the help function directly on the pyclesperanto package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package pyclesperanto:\n",
      "\n",
      "NAME\n",
      "    pyclesperanto\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    _pyclesperanto\n",
      "\n",
      "FUNCTIONS\n",
      "    add_image_and_scalar(...) method of builtins.PyCapsule instance\n",
      "        add_image_and_scalar(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data, scalar: float = 0) -> None\n",
      "        \n",
      "        Add buffer and scalar\n",
      "    \n",
      "    connected_components_labeling_box(...) method of builtins.PyCapsule instance\n",
      "        connected_components_labeling_box(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data) -> None\n",
      "        \n",
      "        copy data\n",
      "    \n",
      "    copy(...) method of builtins.PyCapsule instance\n",
      "        copy(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data) -> None\n",
      "        \n",
      "        copy data\n",
      "    \n",
      "    gaussian_blur(...) method of builtins.PyCapsule instance\n",
      "        gaussian_blur(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data, sigma_x: float = 0, sigma_y: float = 0, sigma_z: float = 0) -> None\n",
      "        \n",
      "        Apply gaussian blur\n",
      "    \n",
      "    maximum_all_pixels(...) method of builtins.PyCapsule instance\n",
      "        maximum_all_pixels(device: pyclesperanto._pyclesperanto.gpu, input: pyclesperanto._pyclesperanto.data, output: pyclesperanto._pyclesperanto.data) -> None\n",
      "        \n",
      "        return maximum pixel value\n",
      "\n",
      "DATA\n",
      "    __common_alias__ = 'cle'\n",
      "\n",
      "VERSION\n",
      "    0.1.0\n",
      "\n",
      "FILE\n",
      "    /mnt/data/workspace/C++/clEsperanto/pyclesperanto/pyclesperanto/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pycle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (opencl)",
   "language": "python",
   "name": "opencl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
